{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9950b06-4ccb-4292-a03b-1e144807a50f"
      },
      "source": [
        "# Gradient descent in depth\n",
        "\n",
        "*Fraida Fund*"
      ],
      "id": "b9950b06-4ccb-4292-a03b-1e144807a50f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "988624ab-9137-4be0-bf6d-ff01bb471fa2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "colors = sns.color_palette(\"hls\", 4)\n",
        "\n",
        "# for 3d interactive plots\n",
        "from ipywidgets import interact, fixed, widgets\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "id": "988624ab-9137-4be0-bf6d-ff01bb471fa2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b23a23c-16e4-47f0-83c1-fd5a6ce41398"
      },
      "source": [
        "## Gradient descent for simple linear regression"
      ],
      "id": "3b23a23c-16e4-47f0-83c1-fd5a6ce41398"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d83a469-99e1-4a82-b1e4-16d22b6f547c"
      },
      "source": [
        "### Generate data"
      ],
      "id": "3d83a469-99e1-4a82-b1e4-16d22b6f547c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c54641a-3c3c-49b2-8c92-0b32e1d581aa"
      },
      "outputs": [],
      "source": [
        "def generate_linear_regression_data(n=100, d=1, coef=[5], intercept=1, sigma=0):\n",
        "  x = np.random.randn(n,d)\n",
        "  y = (np.dot(x, coef) + intercept).squeeze() + sigma * np.random.randn(n)\n",
        "  return x, y"
      ],
      "id": "4c54641a-3c3c-49b2-8c92-0b32e1d581aa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7865779-5d80-415f-9f9b-fe2e037d1d6a"
      },
      "outputs": [],
      "source": [
        "# y = 2 + 3x\n",
        "w_true = np.array([2, 3])\n",
        "n_samples = 100"
      ],
      "id": "e7865779-5d80-415f-9f9b-fe2e037d1d6a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9d5a512-fa3c-408d-95c8-0c96f758f31e"
      },
      "outputs": [],
      "source": [
        "x, y = generate_linear_regression_data(n=n_samples, d=1, coef=w_true[1:], intercept= w_true[0])"
      ],
      "id": "b9d5a512-fa3c-408d-95c8-0c96f758f31e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f066381-1793-4add-a720-f03fa90bd456"
      },
      "outputs": [],
      "source": [
        "# create the \"design matrix\" with a ones column at beginning\n",
        "X = np.hstack((np.ones((n_samples, 1)), x))\n",
        "X.shape"
      ],
      "id": "3f066381-1793-4add-a720-f03fa90bd456"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3a7061b-4591-4462-b8bd-67e089c3f68e"
      },
      "source": [
        "### Define a descent step"
      ],
      "id": "e3a7061b-4591-4462-b8bd-67e089c3f68e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "914c75e6-9e79-4275-a353-ad629c4bf9b4"
      },
      "source": [
        "In each gradient descent step, we will compute\n",
        "\n",
        "$$\n",
        "w^{t+1} = w^t - \\alpha^t \\nabla L(w^t)  \n",
        "$$\n",
        "\n",
        "With a mean squared error loss function\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "L(w) &= \\frac{1}{n} \\sum_{i=1}^n (y_i - \\langle w,x_i \\rangle)^2 \\\\\n",
        "     &= \\frac{1}{n} \\|y - Xw\\|^2\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "we will compute the weights at each step as\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "w^{t+1} &= w^t + \\frac{\\alpha^t}{n} \\sum_{i=1}^n (y_i - \\langle w^t,x_i \\rangle) x_i \\\\\n",
        "        &= w^t + \\frac{\\alpha^t}{n} X^T (y - X w^t)                  \n",
        "\\end{aligned}\n",
        "$$"
      ],
      "id": "914c75e6-9e79-4275-a353-ad629c4bf9b4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a477d80-8046-4e0d-8b9a-8f7f18109365"
      },
      "outputs": [],
      "source": [
        "def gd_step(w, X, y, lr):\n",
        "  # use current parameters to get y_hat\n",
        "  y_hat = np.dot(X,w)\n",
        "  error = y_hat-y\n",
        "  # compute gradient for this y_hat\n",
        "  grad = np.matmul(X.T, error)\n",
        "  # update weights\n",
        "  w_new = w - (lr/X.shape[0])*grad\n",
        "\n",
        "  # we don't have to actually compute MSE\n",
        "  # but I want to, for visualization\n",
        "  mse = np.mean(error**2, axis=0)\n",
        "\n",
        "  return (w_new, mse, grad)"
      ],
      "id": "1a477d80-8046-4e0d-8b9a-8f7f18109365"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "480de152-ee1b-407f-9e16-47b7dc536819"
      },
      "source": [
        "Note: in the update rule, the signs are different from the expression above because we switched the order of the terms in the error expression: we used $\\hat{y} - y$."
      ],
      "id": "480de152-ee1b-407f-9e16-47b7dc536819"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d48863ec-ead0-44e8-8b4c-b47c6366fda7"
      },
      "source": [
        "### Perform gradient descent"
      ],
      "id": "d48863ec-ead0-44e8-8b4c-b47c6366fda7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b2cdb23-b9e2-4ef5-ba96-065384d15a7e"
      },
      "outputs": [],
      "source": [
        "# gradient descent settings: number of iterations, learning rate, starting point\n",
        "itr = 50\n",
        "lr = 0.1\n",
        "w_init = np.random.uniform(3,7,len(w_true))\n",
        "print(w_init)"
      ],
      "id": "3b2cdb23-b9e2-4ef5-ba96-065384d15a7e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30f42f32-db36-4c46-beab-f2274cd16893"
      },
      "outputs": [],
      "source": [
        "w_steps = np.zeros((itr, len(w_init)))\n",
        "mse_steps = np.zeros(itr)\n",
        "grad_steps = np.zeros((itr, len(w_init)))\n",
        "\n",
        "w_star = w_init\n",
        "for i in range(itr):\n",
        "  w_star, mse, gradient = gd_step(w_star, X, y, lr)\n",
        "  w_steps[i] = w_star\n",
        "  mse_steps[i] = mse\n",
        "  grad_steps[i] = gradient"
      ],
      "id": "30f42f32-db36-4c46-beab-f2274cd16893"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1515e5e1-a594-4161-a3f6-4f43360247c7"
      },
      "source": [
        "### Visualize"
      ],
      "id": "1515e5e1-a594-4161-a3f6-4f43360247c7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60f58dd9-d161-4864-810d-4112297e43a1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,5))\n",
        "plt.subplot(1,3,1);\n",
        "\n",
        "for n, w in enumerate(w_true):\n",
        "  plt.axhline(y=w, linestyle='--', color=colors[n]);\n",
        "  sns.lineplot(x=np.arange(itr), y=w_steps[:,n], color=colors[n]);\n",
        "\n",
        "plt.xlabel(\"Iteration\");\n",
        "plt.ylabel(\"Coefficient Value\");\n",
        "\n",
        "plt.subplot(1,3, 2);\n",
        "sns.lineplot(x=np.arange(itr), y=mse_steps);\n",
        "#plt.yscale(\"log\")\n",
        "plt.xlabel(\"Iteration\");\n",
        "plt.ylabel(\"Training MSE\");\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 3);\n",
        "for n, w in enumerate(w_true):\n",
        "  sns.lineplot(x=np.arange(itr), y=grad_steps[:,n], color=colors[n]);\n",
        "plt.xlabel(\"Iteration\");\n",
        "plt.ylabel(\"Gradient\");\n",
        "\n",
        "plt.suptitle(\"Estimate after %d iterations with rate %s: %s\" %\n",
        "          (itr, \"{0:0.4f}\".format(lr), [\"{0:0.4f}\".format(w) for w in w_star]));"
      ],
      "id": "60f58dd9-d161-4864-810d-4112297e43a1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54936cdb-69c0-4e3d-b318-6c00f15193de"
      },
      "source": [
        "### Other things to try\n",
        "\n",
        "-   What happens if we increase the learning rate?\n",
        "-   What happens if we decrease the learning rate?"
      ],
      "id": "54936cdb-69c0-4e3d-b318-6c00f15193de"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf19ce52-ce53-4ae8-8bd6-6374d25bff58"
      },
      "source": [
        "### Descent path on MSE contour"
      ],
      "id": "bf19ce52-ce53-4ae8-8bd6-6374d25bff58"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4531229-e27f-4dfa-9abb-7b8b4e06d95a"
      },
      "source": [
        "Generating data for a multiple regression (with two features):"
      ],
      "id": "a4531229-e27f-4dfa-9abb-7b8b4e06d95a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80cbc2bc-9e63-4499-923d-a79c78fb044e"
      },
      "outputs": [],
      "source": [
        "w_true = [2, 6, 5]\n",
        "n_samples = 100\n",
        "x, y = generate_linear_regression_data(n=n_samples, d=2, coef=w_true[1:], intercept=w_true[0])\n",
        "X = np.hstack((np.ones((n_samples, 1)), x))\n",
        "X.shape"
      ],
      "id": "80cbc2bc-9e63-4499-923d-a79c78fb044e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "600526e1-ce3a-493f-bf5d-2bd2f1086dd5"
      },
      "outputs": [],
      "source": [
        "# gradient descent settings: number of iterations, learning rate, starting point\n",
        "itr = 50\n",
        "lr = 0.1\n",
        "w_init = np.random.uniform(3, 7, len(w_true))\n",
        "print(w_init)"
      ],
      "id": "600526e1-ce3a-493f-bf5d-2bd2f1086dd5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09ef9b15-781d-4060-a7ec-f665f0e94cb5"
      },
      "outputs": [],
      "source": [
        "w_steps = np.zeros((itr, len(w_init)))\n",
        "mse_steps = np.zeros(itr)\n",
        "grad_steps = np.zeros((itr, len(w_init)))\n",
        "\n",
        "w_star = w_init\n",
        "for i in range(itr):\n",
        "  w_star, mse, gradient = gd_step(w_star, X, y, lr)\n",
        "  w_steps[i] = w_star\n",
        "  mse_steps[i] = mse\n",
        "  grad_steps[i] = gradient"
      ],
      "id": "09ef9b15-781d-4060-a7ec-f665f0e94cb5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00ca85c1-30f0-4170-be68-6cc6d4ef3eba"
      },
      "outputs": [],
      "source": [
        "coefs = np.arange(2, 8, 0.05)\n",
        "\n",
        "coef_grid = np.array(np.meshgrid(coefs, coefs)).reshape(1, 2, coefs.shape[0], coefs.shape[0])\n",
        "y_hat_c = (w_true[0] + np.sum(coef_grid * x.reshape(x.shape[0], 2, 1, 1), axis=1) )\n",
        "mses_coefs = np.mean((y.reshape(-1, 1, 1)- y_hat_c)**2,axis=0)"
      ],
      "id": "00ca85c1-30f0-4170-be68-6cc6d4ef3eba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66817f29-81fa-414b-ae9f-bc54083f14b8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,5));\n",
        "X1, X2 = np.meshgrid(coefs, coefs);\n",
        "p = plt.contour(X1, X2, mses_coefs, levels=5);\n",
        "plt.clabel(p, inline=1, fontsize=10);\n",
        "plt.xlabel('w1');\n",
        "plt.ylabel('w2');\n",
        "sns.lineplot(x=w_steps[:,1], y=w_steps[:,2], color='black', sort=False, alpha=0.5);\n",
        "sns.scatterplot(x=w_steps[:,1], y=w_steps[:,2], hue=np.arange(itr), edgecolor=None);\n",
        "plt.scatter(w_true[1], w_true[2], c='black', marker='*');\n",
        "plt.title(\"Estimate after %d iterations with rate %s: %s\" % (itr, \"{0:0.4f}\".format(lr), [\"{0:0.4f}\".format(w) for w in w_star]));\n"
      ],
      "id": "66817f29-81fa-414b-ae9f-bc54083f14b8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbfc8736-d5ff-46b3-b5d6-46dbd6a20a4b"
      },
      "outputs": [],
      "source": [
        "def plot_3D(elev=20, azim=-20, X1=X1, X2=X2, mses_coefs=mses_coefs,\n",
        "            w_steps=w_steps, mse_steps=mse_steps):\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    ax = plt.subplot(projection='3d')\n",
        "\n",
        "    # Plot the surface.\n",
        "    ax.plot_surface(X1, X2, mses_coefs, alpha=0.5, cmap=cm.coolwarm,\n",
        "                          linewidth=0, antialiased=False)\n",
        "    ax.scatter3D(w_steps[:, 1], w_steps[:, 2], mse_steps, s=5, color='black')\n",
        "    ax.plot(w_steps[:, 1], w_steps[:, 2], mse_steps, color='gray')\n",
        "\n",
        "    ax.view_init(elev=elev, azim=azim)\n",
        "    ax.set_xlabel('w1')\n",
        "    ax.set_ylabel('w2')\n",
        "    ax.set_zlabel('MSE')\n",
        "    plt.show()\n",
        "\n",
        "interact(plot_3D, elev=widgets.IntSlider(min=-90, max=90, step=10, value=20),\n",
        "          azim=widgets.IntSlider(min=-90, max=90, step=10, value=20),\n",
        "         X1=fixed(X1), X2=fixed(X2), mses_coefs=fixed(mses_coefs),\n",
        "         w_steps=fixed(w_steps), mse_steps=fixed(mse_steps));"
      ],
      "id": "fbfc8736-d5ff-46b3-b5d6-46dbd6a20a4b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bcc0166-c563-4d63-8329-0580c87b9e33"
      },
      "source": [
        "## Stochastic gradient descent\n",
        "\n",
        "For stochastic gradient descent, we will compute the gradient and update the weights using one sample (or a mini-batch of samples) in each step.\n",
        "\n",
        "**A note on sampling**: In practice, the samples are often sampled without replacement, but the statistical guarantee of convergence is for sampling with replacement. In this example, we sample with replacement. You can read more about different varieties of gradient descent and stochastic gradient descent in [How is stochastic gradient descent implemented in the context of machine learning and deep learning](https://sebastianraschka.com/faq/docs/sgd-methods.html)."
      ],
      "id": "5bcc0166-c563-4d63-8329-0580c87b9e33"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e70755a-f064-4775-8618-5b1691e333a6"
      },
      "source": [
        "### Define a stochastic descent step"
      ],
      "id": "4e70755a-f064-4775-8618-5b1691e333a6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ce46a2a-7bb4-4b37-85a7-6737fa4a625e"
      },
      "outputs": [],
      "source": [
        "def sgd_step(w, X, y, lr, n):\n",
        "\n",
        "  idx_sample = np.random.choice(X.shape[0], n, replace=True)\n",
        "\n",
        "  X_sample = X[idx_sample, :]\n",
        "  y_sample = y[idx_sample]\n",
        "\n",
        "  # use current parameters to get y_hat\n",
        "  y_hat = np.dot(X_sample,w)\n",
        "  error = y_hat-y_sample\n",
        "  # compute gradient for this y_hat\n",
        "  grad = np.matmul(X_sample.T, error)\n",
        "  # update weights\n",
        "  w_new = w - (lr/n)*grad\n",
        "\n",
        "  # we don't have to actually compute MSE\n",
        "  # but I want to, for visualization\n",
        "  # note: MSE is computed on entire data, not sample\n",
        "  mse = np.mean((y-np.dot(X, w))**2, axis=0)\n",
        "\n",
        "  return (w_new, mse, grad)"
      ],
      "id": "2ce46a2a-7bb4-4b37-85a7-6737fa4a625e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42bd8603-610d-49ef-ba8d-2d4bf0f3034c"
      },
      "source": [
        "### Perform stochastic gradient descent"
      ],
      "id": "42bd8603-610d-49ef-ba8d-2d4bf0f3034c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "243d109e-83b4-41bf-8bef-89b5614abaaa"
      },
      "outputs": [],
      "source": [
        "# now we have another gradient descent option: how many samples in a \"batch\"\n",
        "itr = 50\n",
        "lr = 0.1\n",
        "n_batch = 1\n",
        "w_init = [w_true[0], 2, 8]"
      ],
      "id": "243d109e-83b4-41bf-8bef-89b5614abaaa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d4e18fe-aece-4d6a-9b1f-edc4f0ae9b0b"
      },
      "outputs": [],
      "source": [
        "w_steps = np.zeros((itr, len(w_init)))\n",
        "mse_steps = np.zeros(itr)\n",
        "\n",
        "w_star = w_init\n",
        "for i in range(itr):\n",
        "  w_star, mse, grad = sgd_step(w_star, X, y, lr, n_batch)\n",
        "  w_steps[i] = w_star\n",
        "  mse_steps[i] = mse"
      ],
      "id": "3d4e18fe-aece-4d6a-9b1f-edc4f0ae9b0b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38583dfb-c27a-4fe6-87e7-10bfdb9bbb74"
      },
      "source": [
        "### Visualize"
      ],
      "id": "38583dfb-c27a-4fe6-87e7-10bfdb9bbb74"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "049abdfc-4823-432a-8623-8a5af9f41a44"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,5))\n",
        "plt.subplot(1,3,1);\n",
        "\n",
        "for n, w in enumerate(w_true):\n",
        "  plt.axhline(y=w, linestyle='--', color=colors[n]);\n",
        "  sns.lineplot(x=np.arange(itr), y=w_steps[:,n], color=colors[n], label='w' + str(n));\n",
        "plt.xlabel(\"Iteration\");\n",
        "plt.ylabel(\"Coefficient Value\");\n",
        "\n",
        "plt.subplot(1, 3, 2);\n",
        "sns.lineplot(x=np.arange(itr), y=mse_steps);\n",
        "#plt.yscale(\"log\")\n",
        "plt.xlabel(\"Iteration\");\n",
        "plt.ylabel(\"Training MSE\");\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 3);\n",
        "X1, X2 = np.meshgrid(coefs, coefs);\n",
        "p = plt.contour(X1, X2, mses_coefs, levels=5);\n",
        "plt.clabel(p, inline=1, fontsize=10);\n",
        "plt.xlabel('w1');\n",
        "plt.ylabel('w2');\n",
        "sns.lineplot(x=w_steps[:,1], y=w_steps[:,2], color='black', sort=False, alpha=0.5);\n",
        "sns.scatterplot(x=w_steps[:,1], y=w_steps[:,2], hue=np.arange(itr), edgecolor=None);\n",
        "plt.scatter(w_true[1], w_true[2], c='black', marker='*');\n",
        "\n",
        "plt.suptitle(\"Estimate after %d iterations with rate %s and batch size %d: %s\" %\n",
        "            (itr, \"{0:0.4f}\".format(lr), n_batch, [\"{0:0.4f}\".format(w) for w in w_star]));"
      ],
      "id": "049abdfc-4823-432a-8623-8a5af9f41a44"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68c494fd-3e50-49f3-be4e-964bfdca11eb"
      },
      "outputs": [],
      "source": [
        "def plot_3D(elev=20, azim=-20, X1=X1, X2=X2, mses_coefs=mses_coefs,\n",
        "            w_steps=w_steps, mse_steps=mse_steps):\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    ax = plt.subplot(projection='3d')\n",
        "\n",
        "\n",
        "    # Plot the surface.\n",
        "    ax.plot_surface(X1, X2, mses_coefs, alpha=0.5, cmap=cm.coolwarm,\n",
        "                          linewidth=0, antialiased=False)\n",
        "    ax.scatter3D(w_steps[:, 1], w_steps[:, 2], mse_steps, s=5, color='black')\n",
        "    ax.plot(w_steps[:, 1], w_steps[:, 2], mse_steps, color='gray')\n",
        "\n",
        "\n",
        "    ax.view_init(elev=elev, azim=azim)\n",
        "    ax.set_xlabel('w1')\n",
        "    ax.set_ylabel('w2')\n",
        "    ax.set_zlabel('MSE')\n",
        "    plt.show()\n",
        "\n",
        "interact(plot_3D, elev=widgets.IntSlider(min=-90, max=90, step=10, value=20),\n",
        "          azim=widgets.IntSlider(min=-90, max=90, step=10, value=20),\n",
        "         X1=fixed(X1), X2=fixed(X2), mses_coefs=fixed(mses_coefs),\n",
        "         w_steps=fixed(w_steps), mse_steps=fixed(mse_steps));\n"
      ],
      "id": "68c494fd-3e50-49f3-be4e-964bfdca11eb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2971971c-3f88-4d0a-b08e-8bbd9c2b8c15"
      },
      "source": [
        "### Other things to try\n",
        "\n",
        "-   Increase number of samples used in each iteration?\n",
        "-   Increase learning rate?\n",
        "-   Decrease learning rate?\n",
        "-   Use decaying learning rate $\\alpha^t = \\frac{\\alpha_0}{1 + kt}$?"
      ],
      "id": "2971971c-3f88-4d0a-b08e-8bbd9c2b8c15"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fa69dd1-638d-43bf-945c-2d61f1452320"
      },
      "source": [
        "## Gradient descent with noise"
      ],
      "id": "3fa69dd1-638d-43bf-945c-2d61f1452320"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "771df4cc-60c2-412e-9dac-ba2ca71f09f6"
      },
      "source": [
        "### Generate noisy data\n",
        "\n",
        "This time, we will use the `sigma` argument in our `generate_linear_regression_data` function to generate data that does not perfectly fit a linear model. (Using the same coefficients as the previous example.)"
      ],
      "id": "771df4cc-60c2-412e-9dac-ba2ca71f09f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af69c7cb-d3ef-46dc-9641-9da71b15a4e0"
      },
      "outputs": [],
      "source": [
        "x, y = generate_linear_regression_data(n=n_samples, d=2, coef=w_true[1:], intercept=w_true[0], sigma=3)\n",
        "X = np.column_stack((np.ones((n_samples, 1)), x))"
      ],
      "id": "af69c7cb-d3ef-46dc-9641-9da71b15a4e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a5cba5f-1cab-44f3-81ab-78634b4658b5"
      },
      "source": [
        "### Perform gradient descent on noisy data"
      ],
      "id": "9a5cba5f-1cab-44f3-81ab-78634b4658b5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b517d38-cbf9-4763-a634-b5334e652f60"
      },
      "outputs": [],
      "source": [
        "itr = 50\n",
        "lr = 0.1\n",
        "w_init = [w_true[0], 2, 8]"
      ],
      "id": "9b517d38-cbf9-4763-a634-b5334e652f60"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74b4a93f-d281-467c-830f-df14320ea2d1"
      },
      "outputs": [],
      "source": [
        "w_steps = np.zeros((itr, len(w_init)))\n",
        "mse_steps = np.zeros(itr)\n",
        "\n",
        "w_star = w_init\n",
        "for i in range(itr):\n",
        "  w_star, mse, gradient = gd_step(w_star, X, y, lr)\n",
        "  w_steps[i] = w_star\n",
        "  mse_steps[i] = mse"
      ],
      "id": "74b4a93f-d281-467c-830f-df14320ea2d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "419239a1-f2cc-4743-9e27-da3ff7b3bb8b"
      },
      "source": [
        "### Visualize gradient descent on noisy data\n",
        "\n",
        "This time, the gradient descent may not necessarily arrive at the “true” coefficient values. That’s not because it does not find the coefficients with minimum MSE; it’s because the coefficients with minimum MSE on the noisy training data are not necessarily the “true” coefficients."
      ],
      "id": "419239a1-f2cc-4743-9e27-da3ff7b3bb8b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8e29603-5d31-44f0-83ac-314204a9bfba"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,5))\n",
        "plt.subplot(1,3,1);\n",
        "\n",
        "for n, w in enumerate(w_true):\n",
        "  plt.axhline(y=w, linestyle='--', color=colors[n]);\n",
        "  sns.lineplot(x=np.arange(itr), y=w_steps[:,n], color=colors[n], label='w' + str(n));\n",
        "plt.xlabel(\"Iteration\");\n",
        "plt.ylabel(\"Coefficient Value\");\n",
        "\n",
        "plt.subplot(1, 3, 2);\n",
        "sns.lineplot(x=np.arange(itr), y=mse_steps);\n",
        "#plt.yscale(\"log\")\n",
        "plt.xlabel(\"Iteration\");\n",
        "plt.ylabel(\"Training MSE\");\n",
        "\n",
        "plt.subplot(1, 3, 3);\n",
        "X1, X2 = np.meshgrid(coefs, coefs);\n",
        "p = plt.contour(X1, X2, mses_coefs, levels=5);\n",
        "plt.clabel(p, inline=1, fontsize=10);\n",
        "plt.xlabel('w1');\n",
        "plt.ylabel('w2');\n",
        "sns.lineplot(x=w_steps[:,1], y=w_steps[:,2], color='black', sort=False, alpha=0.5);\n",
        "sns.scatterplot(x=w_steps[:,1], y=w_steps[:,2], hue=np.arange(itr), edgecolor=None);\n",
        "plt.scatter(w_true[1], w_true[2], c='black', marker='*');\n",
        "\n",
        "plt.suptitle(\"Estimate after %d iterations with rate %s: %s\" %\n",
        "          (itr, \"{0:0.4f}\".format(lr), [\"{0:0.4f}\".format(w) for w in w_star]));"
      ],
      "id": "d8e29603-5d31-44f0-83ac-314204a9bfba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcdab861-cfca-4ce4-a55e-9c1682469ff1"
      },
      "source": [
        "### Perform stochastic gradient descent on noisy data"
      ],
      "id": "fcdab861-cfca-4ce4-a55e-9c1682469ff1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e56a43bc-c6ea-4749-b399-1c1082e7c611"
      },
      "outputs": [],
      "source": [
        "itr = 100\n",
        "lr = 0.1\n",
        "n_batch = 1\n",
        "w_init = [w_true[0], 2, 8]"
      ],
      "id": "e56a43bc-c6ea-4749-b399-1c1082e7c611"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "248160c6-caef-4f69-9334-2edf1d595ff7"
      },
      "outputs": [],
      "source": [
        "w_steps = np.zeros((itr, len(w_init)))\n",
        "mse_steps = np.zeros(itr)\n",
        "\n",
        "w_star = w_init\n",
        "for i in range(itr):\n",
        "  w_star, mse, grad = sgd_step(w_star, X, y, lr, n_batch)\n",
        "  w_steps[i] = w_star\n",
        "  mse_steps[i] = mse"
      ],
      "id": "248160c6-caef-4f69-9334-2edf1d595ff7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f8915c9-0532-4d6a-a922-2e10e4e49b33"
      },
      "source": [
        "### Visualize stochastic gradient descent\n",
        "\n",
        "Note the “noise ball”!"
      ],
      "id": "4f8915c9-0532-4d6a-a922-2e10e4e49b33"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e8a7906-d048-4a7e-ad9a-5cfea6618efb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,5))\n",
        "plt.subplot(1,3,1);\n",
        "\n",
        "for n, w in enumerate(w_true):\n",
        "  plt.axhline(y=w, linestyle='--', color=colors[n]);\n",
        "  sns.lineplot(x=np.arange(itr), y=w_steps[:,n], color=colors[n], label='w' + str(n));\n",
        "plt.xlabel(\"Iteration\");\n",
        "plt.ylabel(\"Coefficient Value\");\n",
        "\n",
        "plt.subplot(1, 3, 2);\n",
        "sns.lineplot(x=np.arange(itr), y=mse_steps);\n",
        "#plt.yscale(\"log\")\n",
        "plt.xlabel(\"Iteration\");\n",
        "plt.ylabel(\"Training MSE\");\n",
        "\n",
        "plt.subplot(1, 3, 3);\n",
        "X1, X2 = np.meshgrid(coefs, coefs);\n",
        "p = plt.contour(X1, X2, mses_coefs, levels=5);\n",
        "plt.clabel(p, inline=1, fontsize=10);\n",
        "plt.xlabel('w1');\n",
        "plt.ylabel('w2');\n",
        "sns.lineplot(x=w_steps[:,1], y=w_steps[:,2], color='black', sort=False, alpha=0.5);\n",
        "sns.scatterplot(x=w_steps[:,1], y=w_steps[:,2], hue=np.arange(itr), edgecolor=None);\n",
        "plt.scatter(w_true[1], w_true[2], c='black', marker='*');\n",
        "\n",
        "plt.suptitle(\"Estimate after %d iterations with rate %s and batch size %d: %s\" %\n",
        "            (itr, \"{0:0.4f}\".format(lr), n_batch, [\"{0:0.4f}\".format(w) for w in w_star]));\n"
      ],
      "id": "5e8a7906-d048-4a7e-ad9a-5cfea6618efb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7042da04-0020-4078-a99d-f22ad54d7105"
      },
      "source": [
        "## Interactive\n",
        "\n",
        "You can use this interactive to explore different gradient descent options and see the effect."
      ],
      "id": "7042da04-0020-4078-a99d-f22ad54d7105"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b04faa0e-1467-4b80-abd0-e457750fea72"
      },
      "outputs": [],
      "source": [
        "n_samples = 100\n",
        "w_true = [2, 6, 5]\n",
        "x, y = generate_linear_regression_data(n=n_samples, d=2, coef=w_true[1:], intercept=w_true[0], sigma=0)\n",
        "X = np.hstack((np.ones((n_samples, 1)), x))\n",
        "\n",
        "@interact(itr = widgets.IntSlider(min=10, max=200, step=10, value=100),\n",
        "          lr = widgets.FloatSlider(min=0.05, max=0.95, step=0.05, value=0.1),\n",
        "          n_batch = widgets.IntSlider(min=1, max=100, step=1, value=100),\n",
        "          sigma = widgets.FloatSlider(min=0, max=5, step=0.5, value=1),\n",
        "          X = fixed(X), y = fixed(y))\n",
        "def plot_gd(itr, lr, n_batch, sigma, X, y):\n",
        "\n",
        "  y = y + sigma * np.random.randn(n_samples)\n",
        "\n",
        "  w_init = [w_true[0], 3, 7]\n",
        "  w_steps = np.zeros((itr, len(w_init)))\n",
        "  mse_steps = np.zeros(itr)\n",
        "\n",
        "  w_star = w_init\n",
        "  for i in range(itr):\n",
        "    w_star, mse, grad = sgd_step(w_star, X, y, lr, n_batch)\n",
        "    w_steps[i] = w_star\n",
        "    mse_steps[i] = mse\n",
        "\n",
        "  plt.figure(figsize=(18,5))\n",
        "  plt.subplot(1,3,1);\n",
        "\n",
        "  for n, w in enumerate(w_true):\n",
        "    plt.axhline(y=w, linestyle='--', color=colors[n]);\n",
        "    sns.lineplot(x=np.arange(itr), y=w_steps[:,n], color=colors[n], label='w' + str(n));\n",
        "  plt.xlabel(\"Iteration\");\n",
        "  plt.ylabel(\"Coefficient Value\");\n",
        "\n",
        "  plt.subplot(1, 3, 2);\n",
        "  sns.lineplot(x=np.arange(itr), y=mse_steps);\n",
        "  #plt.yscale(\"log\")\n",
        "  plt.xlabel(\"Iteration\");\n",
        "  plt.ylabel(\"Training MSE\");\n",
        "\n",
        "  plt.subplot(1, 3, 3);\n",
        "  X1, X2 = np.meshgrid(coefs, coefs);\n",
        "  p = plt.contour(X1, X2, mses_coefs, levels=5);\n",
        "  plt.clabel(p, inline=1, fontsize=10);\n",
        "  plt.xlabel('w1');\n",
        "  plt.ylabel('w2');\n",
        "  sns.lineplot(x=w_steps[:,1], y=w_steps[:,2], color='black', sort=False, alpha=0.5);\n",
        "  sns.scatterplot(x=w_steps[:,1], y=w_steps[:,2], hue=np.arange(itr), edgecolor=None);\n",
        "  plt.scatter(w_true[1], w_true[2], c='black', marker='*');\n",
        "\n",
        "  plt.suptitle(\"Estimate after %d iterations with rate %s and batch size %d: %s\" %\n",
        "              (itr, \"{0:0.4f}\".format(lr), n_batch, [\"{0:0.4f}\".format(w) for w in w_star]));\n",
        "  plt.show()"
      ],
      "id": "b04faa0e-1467-4b80-abd0-e457750fea72"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9e7d7fb-6b22-4ba5-b835-7b893f36c613"
      },
      "source": [
        "## A less friendly loss surface"
      ],
      "id": "d9e7d7fb-6b22-4ba5-b835-7b893f36c613"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eeb9de8-9afa-4bfa-83b2-d163c238391f"
      },
      "outputs": [],
      "source": [
        "w_true = [2, 5, 4]"
      ],
      "id": "2eeb9de8-9afa-4bfa-83b2-d163c238391f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9321a7ab-951e-43d7-8986-e6c867d98be5"
      },
      "outputs": [],
      "source": [
        "n_samples = 1000\n",
        "d = 1\n",
        "sigma = 1\n",
        "\n",
        "x1 = np.random.randn(n_samples,d)\n",
        "x2 = x1 + (sigma/5)*np.random.randn(n_samples,1)\n",
        "x = np.column_stack([x1, x2])\n",
        "y = (np.dot(x, w_true[1:]) + w_true[0]).squeeze() + sigma * np.random.randn(n_samples)\n",
        "\n",
        "\n",
        "X = np.column_stack((np.ones((n_samples, 1)), x))"
      ],
      "id": "9321a7ab-951e-43d7-8986-e6c867d98be5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "547f9f45-232a-48a3-900d-3816c139bc8d"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x=x1.squeeze(), y=x2.squeeze());\n",
        "plt.xlabel('x1');\n",
        "plt.ylabel('x2');"
      ],
      "id": "547f9f45-232a-48a3-900d-3816c139bc8d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14e0efb1-4ba0-414e-84f3-3b28c7e7ea7a"
      },
      "source": [
        "### MSE contour"
      ],
      "id": "14e0efb1-4ba0-414e-84f3-3b28c7e7ea7a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f02a3bb-3ea7-4ce5-aa8f-3e3a1da0db13"
      },
      "outputs": [],
      "source": [
        "coefs = np.arange(3, 7, 0.02)\n",
        "\n",
        "coef_grid = np.array(np.meshgrid(coefs, coefs)).reshape(1, 2, coefs.shape[0], coefs.shape[0])\n",
        "y_hat_c = (w_true[0] + np.sum(coef_grid * x.reshape(x.shape[0], 2, 1, 1), axis=1) )\n",
        "mses_coefs = np.mean((y.reshape(-1, 1, 1)- y_hat_c)**2,axis=0)"
      ],
      "id": "4f02a3bb-3ea7-4ce5-aa8f-3e3a1da0db13"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6a90a90-eb9d-4f36-992c-a13350dc45cd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,5));\n",
        "X1, X2 = np.meshgrid(coefs, coefs)\n",
        "p = plt.contour(X1, X2, mses_coefs, levels=15);\n",
        "plt.clabel(p, inline=1, fontsize=10);\n",
        "plt.xlabel('w1');\n",
        "plt.ylabel('w2');\n",
        "plt.scatter(w_true[1], w_true[2], c='black', marker='*');\n"
      ],
      "id": "f6a90a90-eb9d-4f36-992c-a13350dc45cd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "802b56c4-ad29-49af-b825-02d70717faeb"
      },
      "source": [
        "### Perform gradient descent"
      ],
      "id": "802b56c4-ad29-49af-b825-02d70717faeb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b099c8b8-461a-449d-85fc-4db0bc3068ab"
      },
      "outputs": [],
      "source": [
        "itr = 100\n",
        "lr = 0.1\n",
        "w_init = [w_true[0], 3, 7]"
      ],
      "id": "b099c8b8-461a-449d-85fc-4db0bc3068ab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea7460a7-3f7b-4536-95a9-f799d43e08c8"
      },
      "outputs": [],
      "source": [
        "w_steps = np.zeros((itr, len(w_init)))\n",
        "mse_steps = np.zeros(itr)\n",
        "grad_steps = np.zeros((itr, len(w_init)))\n",
        "\n",
        "w_star = w_init\n",
        "for i in range(itr):\n",
        "  w_star, mse, gradient = gd_step(w_star, X, y, lr)\n",
        "  w_steps[i] = w_star\n",
        "  mse_steps[i] = mse\n",
        "  grad_steps[i] = gradient"
      ],
      "id": "ea7460a7-3f7b-4536-95a9-f799d43e08c8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7357a4f5-21eb-4898-9b86-324395f26a16"
      },
      "source": [
        "### Visualize gradient descent"
      ],
      "id": "7357a4f5-21eb-4898-9b86-324395f26a16"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72c62d1e-9daa-47a0-9fa5-17b005c5be26"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,5))\n",
        "plt.subplot(1,3,1);\n",
        "\n",
        "for n, w in enumerate(w_true):\n",
        "  plt.axhline(y=w, linestyle='--', color=colors[n]);\n",
        "  sns.lineplot(x=np.arange(itr), y=w_steps[:,n], color=colors[n], label='w' + str(n));\n",
        "plt.xlabel(\"Iteration\");\n",
        "plt.ylabel(\"Coefficient Value\");\n",
        "\n",
        "plt.subplot(1, 3, 2);\n",
        "sns.lineplot(x=np.arange(itr), y=mse_steps);\n",
        "#plt.yscale(\"log\")\n",
        "plt.xlabel(\"Iteration\");\n",
        "plt.ylabel(\"Training MSE\");\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 3);\n",
        "X1, X2 = np.meshgrid(coefs, coefs);\n",
        "p = plt.contour(X1, X2, mses_coefs, levels=5);\n",
        "plt.clabel(p, inline=1, fontsize=10);\n",
        "plt.xlabel('w1');\n",
        "plt.ylabel('w2');\n",
        "sns.lineplot(x=w_steps[:,1], y=w_steps[:,2], color='black', sort=False, alpha=0.5);\n",
        "sns.scatterplot(x=w_steps[:,1], y=w_steps[:,2], hue=np.arange(itr), edgecolor=None);\n",
        "plt.scatter(w_true[1], w_true[2], c='black', marker='*');\n",
        "\n",
        "plt.suptitle(\"Estimate after %d iterations with rate %s: %s\" %\n",
        "          (itr, \"{0:0.4f}\".format(lr), [\"{0:0.4f}\".format(w) for w in w_star]));"
      ],
      "id": "72c62d1e-9daa-47a0-9fa5-17b005c5be26"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53050c7e-1bce-47ec-8af0-acb2bee03b93"
      },
      "source": [
        "### Other things to try\n",
        "\n",
        "-   What happens if we increase the learning rate (try e.g. 0.9)?\n",
        "-   What happens if we change the initial “guess”?"
      ],
      "id": "53050c7e-1bce-47ec-8af0-acb2bee03b93"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d5a3320-18d4-48a0-8f52-4202fd1be3e8"
      },
      "source": [
        "### Momentum"
      ],
      "id": "4d5a3320-18d4-48a0-8f52-4202fd1be3e8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "702cafd3-c612-4e8a-bcfe-1340ef39e438"
      },
      "outputs": [],
      "source": [
        "def gd_step_momentum(w, X, y, lr, eta, v):\n",
        "  # use current parameters to get y_hat, error\n",
        "  y_hat = np.dot(X,w)\n",
        "  error = y_hat - y\n",
        "  # compute gradient and velocity\n",
        "  grad = np.matmul(X.T, error)\n",
        "  v_new = eta*v + (1/X.shape[0])*grad\n",
        "  # update weights\n",
        "  w_new = w - lr*v_new\n",
        "\n",
        "  # we don't have to actually compute MSE\n",
        "  # but I want to, for visualization\n",
        "  mse = np.mean(error**2, axis=0)\n",
        "\n",
        "  return (w_new, mse, grad, v_new)"
      ],
      "id": "702cafd3-c612-4e8a-bcfe-1340ef39e438"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f223251a-d78a-4bdd-a919-266d5eac59aa"
      },
      "outputs": [],
      "source": [
        "itr = 100\n",
        "lr = 0.1\n",
        "eta = 0.9\n",
        "w_init = [w_true[0], 3, 7]"
      ],
      "id": "f223251a-d78a-4bdd-a919-266d5eac59aa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d8cfacd-bff9-4a8e-aea0-1be0a1e71ca1"
      },
      "outputs": [],
      "source": [
        "w_steps = np.zeros((itr, len(w_init)))\n",
        "mse_steps = np.zeros(itr)\n",
        "grad_steps = np.zeros((itr, len(w_init)))\n",
        "v_steps = np.zeros((itr, len(w_init)))\n",
        "\n",
        "w_star = w_init\n",
        "velocity = np.zeros(len(w_init))\n",
        "for i in range(itr):\n",
        "  w_star, mse, gradient, velocity = gd_step_momentum(w_star, X, y, lr, eta, velocity)\n",
        "  w_steps[i] = w_star\n",
        "  mse_steps[i] = mse\n",
        "  grad_steps[i] = gradient\n",
        "  v_steps[i] = velocity"
      ],
      "id": "5d8cfacd-bff9-4a8e-aea0-1be0a1e71ca1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a953e2ea-2e9c-473d-a82a-e8c8861b501e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,5))\n",
        "plt.subplot(1,3,1);\n",
        "\n",
        "for n, w in enumerate(w_true):\n",
        "  plt.axhline(y=w, linestyle='--', color=colors[n]);\n",
        "  sns.lineplot(x=np.arange(itr), y=w_steps[:,n], color=colors[n], label='w' + str(n));\n",
        "plt.xlabel(\"Iteration\");\n",
        "plt.ylabel(\"Coefficient Value\");\n",
        "\n",
        "plt.subplot(1, 3, 2);\n",
        "for n, w in enumerate(w_true):\n",
        "  sns.lineplot(x=np.arange(itr), y=v_steps[:,n], color=colors[n]);\n",
        "plt.xlabel(\"Iteration\");\n",
        "plt.ylabel(\"Velocity\");\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 3);\n",
        "X1, X2 = np.meshgrid(coefs, coefs);\n",
        "p = plt.contour(X1, X2, mses_coefs, levels=5);\n",
        "plt.clabel(p, inline=1, fontsize=10);\n",
        "plt.xlabel('w1');\n",
        "plt.ylabel('w2');\n",
        "sns.lineplot(x=w_steps[:,1], y=w_steps[:,2], color='black', sort=False, alpha=0.5);\n",
        "sns.scatterplot(x=w_steps[:,1], y=w_steps[:,2], hue=np.arange(itr), edgecolor=None);\n",
        "plt.scatter(w_true[1], w_true[2], c='black', marker='*');\n",
        "\n",
        "plt.suptitle(\"Estimate after %d iterations with rate %s: %s\" %\n",
        "          (itr, \"{0:0.4f}\".format(lr), [\"{0:0.4f}\".format(w) for w in w_star]));\n"
      ],
      "id": "a953e2ea-2e9c-473d-a82a-e8c8861b501e"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    }
  }
}