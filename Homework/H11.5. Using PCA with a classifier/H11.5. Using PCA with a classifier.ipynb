{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA for dimensionality reduction before classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA (or any other unsupervised dimensionality reduction) can be used to transform data before fitting a supervised learning model. In this problem, we will apply PCA for dimensionality reduction, then use a support vector classifier fitted on a subset of the PCA-transformed features.\n",
    "\n",
    "We will use K-fold cross validation to decide the number of principal components to use, according to the one-SE rule.\n",
    "\n",
    "In this workspace, write code to split the data into training and test sets, and perform the analysis described above on the training set.\n",
    "\n",
    "|Name|\tType|\tDescription|\n",
    "| --- | --- | --- |\n",
    "|`acc_mean`|\t1d numpy array|\tMean validation accuracy for each candidate model.|\n",
    "|`acc_se`|\t1d numpy array|\tStandard error of the mean of validation accuracy for each candidate model.|\n",
    "|`n_pca_opt`|\tinteger|\tOptimal number of components according to 'best mean validation accuracy' rule.|\n",
    "|`n_pca_one_se`|\tinteger|\tOptimal number of components according to 'one SE' rule.|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the `data.csv` file to this workspace, then read in the data to a `numpy` array in `X` and the labels to `y`. If you want to, you can add code to the following cell to explore `X` (for example, see its shape).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.genfromtxt('data.csv',delimiter=',')\n",
    "X = dat[:, :-1]\n",
    "y = dat[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `train_test_split` to split the data into training and test sets. Reserve 30% of the data for the test set. \n",
    "\n",
    "Make sure to shuffle the data, and pass `random_state = 42` so that your random split will match the auto-grader's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the training data to fit a support vector classifier. However, instead of fitting the training data directly, you will first transform it using PCA. Then, you will use only a subset of features - the first `n_comp` principal components - as input to your classifier. \n",
    "\n",
    "You will use K-fold cross validation to find the optimal value of `n_comp`. You should consider every possible value of `n_comp`, from 1 component (simplest possible model) to all of the components (most flexible model).\n",
    "\n",
    "In the next cell,\n",
    "\n",
    "* Use the `sklearn` implementation of `KFold` to iterate over candidate models. In your `KFold`, use 5 splits, and don't shuffle the data (you already shuffled it when dividing into training and test.)\n",
    "* Use the `sklearn` implementation of `PCA` to transform the data. Pass `random_state = 42` to `PCA` so that your result will match the auto-grader's.\n",
    "* Use the `sklearn` implementation of `SVC` to classify the data using the first `n_comp` principal components.  Pass `random_state = 42` to `SVC` so that your result will match the auto-grader's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "n_components = np.arange(1, X_train.shape[1] + 1)\n",
    "acc_mean = np.zeros(len(n_components))\n",
    "acc_se = np.zeros(len(n_components))\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Initialize accuracy lists for each n_components\n",
    "accs = [[] for _ in n_components]\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # Fit PCA with max components ONCE per fold\n",
    "    pca_full = PCA(n_components=X_train.shape[1], random_state=42)\n",
    "    X_train_pca_full = pca_full.fit_transform(X_train_fold)\n",
    "    X_val_pca_full = pca_full.transform(X_val_fold)\n",
    "\n",
    "    for j, n_comp in enumerate(n_components):\n",
    "        # Slice the PCA-transformed data for the current n_components\n",
    "        X_train_pca = X_train_pca_full[:, :n_comp]\n",
    "        X_val_pca = X_val_pca_full[:, :n_comp]\n",
    "\n",
    "        svc = SVC(random_state=42)\n",
    "        svc.fit(X_train_pca, y_train_fold)\n",
    "        y_pred = svc.predict(X_val_pca)\n",
    "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "\n",
    "        accs[j].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean validation accuracy and the standard error of the mean validation accuracy across the folds. Save the results in `acc_mean` and `acc_se`, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "acc_mean = np.array([np.mean(acc) for acc in accs])\n",
    "acc_se = np.array([np.std(acc, ddof=1) / np.sqrt(len(acc)) for acc in accs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, compute the optimal value of `n_comp`, and save this in `n_pca_opt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "n_pca_opt = n_components[np.argmax(acc_mean)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute the optimal `n_comp` according to the one-SE rule, and save this in `n_pca_one_se`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "best_acc = np.max(acc_mean)\n",
    "best_acc_se = acc_se[np.argmax(acc_mean)]\n",
    "threshold = best_acc - best_acc_se\n",
    "n_pca_one_se = n_components[np.where(acc_mean >= threshold)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
