{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNsV2yyFrGIs"
   },
   "source": [
    "# Selecting Logistic Regression Model with K-Fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the attached workspace, you will use K-fold CV to select the regularization strength in an L1-regularized classification model. Then, you will fit the optimal model and evaluate its accuracy on a test set not used for model fitting.\n",
    "\n",
    "You'll need to specify this random state in your notebook:\n",
    "\n",
    "> random_state = 14\n",
    "\n",
    "| Name | Type | Description |\n",
    "| ---- | ---- | ---- |\n",
    "|`Xtr`\t|2d numpy array\t|Training data (features).|\n",
    "|`Xts`\t|2d numpy array\t|Test data (features).|\n",
    "|`ytr`\t|1d numpy array\t|Training data (target).|\n",
    "|`yts`\t|1d numpy array\t|Test data (target).|\n",
    "|`acc_mean`\t|1d numpy array\t|The mean validation accuracy for each model in the K-fold CV.|\n",
    "|`C_best`\t|float\tThe value of the tuning parameter C that yields the best accuracy on the validation data.|\n",
    "|`Xtr_std`\t|2d numpy array\t|Training data (features) after standardizing.|\n",
    "|`Xts_std`\t|2d numpy array\t|Test data (features) after standardizing.|\n",
    "|`y_hat`\t|1d numpy array\t|1d numpy array containing the predictions of the best model for the test set.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LhRjDo48rGIt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z78jhR20rGIu"
   },
   "source": [
    "In this notebook, we are interested in predicting biological characteristics (\"phenotypes\") from gene expression data of mice. Genes are the basic unit in the DNA and encode blueprints for proteins. When proteins are synthesized from a gene, the gene is said to \"express\". Micro-arrays are devices that measure the expression levels of large numbers of genes in parallel. By finding correlations between expression levels and phenotypes, scientists can identify possible genetic markers for biological characteristics.\n",
    "\n",
    "The data in this notebook comes from mice. For each mouse, we have data about expression levels of 77 genes, and we also have some information about the mouse's biological characteristics. For example, some of the mice had Down Syndrome (trisomy), and this is indicated in the `Genotype` column in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Zj0UjAsTrGIv"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data_Cortex_Nuclear.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a quick view of the columns in this data by runnning the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1080 entries, 309_1 to J3295_15\n",
      "Data columns (total 81 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   DYRK1A_N         1077 non-null   float64\n",
      " 1   ITSN1_N          1077 non-null   float64\n",
      " 2   BDNF_N           1077 non-null   float64\n",
      " 3   NR1_N            1077 non-null   float64\n",
      " 4   NR2A_N           1077 non-null   float64\n",
      " 5   pAKT_N           1077 non-null   float64\n",
      " 6   pBRAF_N          1077 non-null   float64\n",
      " 7   pCAMKII_N        1077 non-null   float64\n",
      " 8   pCREB_N          1077 non-null   float64\n",
      " 9   pELK_N           1077 non-null   float64\n",
      " 10  pERK_N           1077 non-null   float64\n",
      " 11  pJNK_N           1077 non-null   float64\n",
      " 12  PKCA_N           1077 non-null   float64\n",
      " 13  pMEK_N           1077 non-null   float64\n",
      " 14  pNR1_N           1077 non-null   float64\n",
      " 15  pNR2A_N          1077 non-null   float64\n",
      " 16  pNR2B_N          1077 non-null   float64\n",
      " 17  pPKCAB_N         1077 non-null   float64\n",
      " 18  pRSK_N           1077 non-null   float64\n",
      " 19  AKT_N            1077 non-null   float64\n",
      " 20  BRAF_N           1077 non-null   float64\n",
      " 21  CAMKII_N         1077 non-null   float64\n",
      " 22  CREB_N           1077 non-null   float64\n",
      " 23  ELK_N            1062 non-null   float64\n",
      " 24  ERK_N            1077 non-null   float64\n",
      " 25  GSK3B_N          1077 non-null   float64\n",
      " 26  JNK_N            1077 non-null   float64\n",
      " 27  MEK_N            1073 non-null   float64\n",
      " 28  TRKA_N           1077 non-null   float64\n",
      " 29  RSK_N            1077 non-null   float64\n",
      " 30  APP_N            1077 non-null   float64\n",
      " 31  Bcatenin_N       1062 non-null   float64\n",
      " 32  SOD1_N           1077 non-null   float64\n",
      " 33  MTOR_N           1077 non-null   float64\n",
      " 34  P38_N            1077 non-null   float64\n",
      " 35  pMTOR_N          1077 non-null   float64\n",
      " 36  DSCR1_N          1077 non-null   float64\n",
      " 37  AMPKA_N          1077 non-null   float64\n",
      " 38  NR2B_N           1077 non-null   float64\n",
      " 39  pNUMB_N          1077 non-null   float64\n",
      " 40  RAPTOR_N         1077 non-null   float64\n",
      " 41  TIAM1_N          1077 non-null   float64\n",
      " 42  pP70S6_N         1077 non-null   float64\n",
      " 43  NUMB_N           1080 non-null   float64\n",
      " 44  P70S6_N          1080 non-null   float64\n",
      " 45  pGSK3B_N         1080 non-null   float64\n",
      " 46  pPKCG_N          1080 non-null   float64\n",
      " 47  CDK5_N           1080 non-null   float64\n",
      " 48  S6_N             1080 non-null   float64\n",
      " 49  ADARB1_N         1080 non-null   float64\n",
      " 50  AcetylH3K9_N     1080 non-null   float64\n",
      " 51  RRP1_N           1080 non-null   float64\n",
      " 52  BAX_N            1080 non-null   float64\n",
      " 53  ARC_N            1080 non-null   float64\n",
      " 54  ERBB4_N          1080 non-null   float64\n",
      " 55  nNOS_N           1080 non-null   float64\n",
      " 56  Tau_N            1080 non-null   float64\n",
      " 57  GFAP_N           1080 non-null   float64\n",
      " 58  GluR3_N          1080 non-null   float64\n",
      " 59  GluR4_N          1080 non-null   float64\n",
      " 60  IL1B_N           1080 non-null   float64\n",
      " 61  P3525_N          1080 non-null   float64\n",
      " 62  pCASP9_N         1080 non-null   float64\n",
      " 63  PSD95_N          1080 non-null   float64\n",
      " 64  SNCA_N           1080 non-null   float64\n",
      " 65  Ubiquitin_N      1080 non-null   float64\n",
      " 66  pGSK3B_Tyr216_N  1080 non-null   float64\n",
      " 67  SHH_N            1080 non-null   float64\n",
      " 68  BAD_N            867 non-null    float64\n",
      " 69  BCL2_N           795 non-null    float64\n",
      " 70  pS6_N            1080 non-null   float64\n",
      " 71  pCFOS_N          1005 non-null   float64\n",
      " 72  SYP_N            1080 non-null   float64\n",
      " 73  H3AcK18_N        900 non-null    float64\n",
      " 74  EGR1_N           870 non-null    float64\n",
      " 75  H3MeK4_N         810 non-null    float64\n",
      " 76  CaNA_N           1080 non-null   float64\n",
      " 77  Genotype         1080 non-null   object \n",
      " 78  Treatment        1080 non-null   object \n",
      " 79  Behavior         1080 non-null   object \n",
      " 80  class            1080 non-null   object \n",
      "dtypes: float64(77), object(4)\n",
      "memory usage: 691.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use \"has Down syndrome\" as the target value to predict. We will prepare a variable `y` whose value is 0 or 1 depending on whether or not the mouse has Down syndrome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt, y = np.unique(df['Genotype'], return_inverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the feature values we will use the gene expression levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = ['DYRK1A_N', 'ITSN1_N', 'BDNF_N', 'NR1_N', 'NR2A_N', 'pAKT_N',\n",
    "       'pBRAF_N', 'pCAMKII_N', 'pCREB_N', 'pELK_N', 'pERK_N', 'pJNK_N',\n",
    "       'PKCA_N', 'pMEK_N', 'pNR1_N', 'pNR2A_N', 'pNR2B_N', 'pPKCAB_N',\n",
    "       'pRSK_N', 'AKT_N', 'BRAF_N', 'CAMKII_N', 'CREB_N', 'ELK_N',\n",
    "       'ERK_N', 'GSK3B_N', 'JNK_N', 'MEK_N', 'TRKA_N', 'RSK_N', 'APP_N',\n",
    "       'Bcatenin_N', 'SOD1_N', 'MTOR_N', 'P38_N', 'pMTOR_N', 'DSCR1_N',\n",
    "       'AMPKA_N', 'NR2B_N', 'pNUMB_N', 'RAPTOR_N', 'TIAM1_N', 'pP70S6_N',\n",
    "       'NUMB_N', 'P70S6_N', 'pGSK3B_N', 'pPKCG_N', 'CDK5_N', 'S6_N',\n",
    "       'ADARB1_N', 'AcetylH3K9_N', 'RRP1_N', 'BAX_N', 'ARC_N', 'ERBB4_N',\n",
    "       'nNOS_N', 'Tau_N', 'GFAP_N', 'GluR3_N', 'GluR4_N', 'IL1B_N',\n",
    "       'P3525_N', 'pCASP9_N', 'PSD95_N', 'SNCA_N', 'Ubiquitin_N',\n",
    "       'pGSK3B_Tyr216_N', 'SHH_N', 'BAD_N', 'BCL2_N', 'pS6_N', 'pCFOS_N',\n",
    "       'SYP_N', 'H3AcK18_N', 'EGR1_N', 'H3MeK4_N', 'CaNA_N']\n",
    "X = df[x_names].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will split the data into training and test sets using `sklearn`'s implementation of `train_test_split`. \n",
    "\n",
    "* Reserve 30% of the data for testing, and leave 70% for training.\n",
    "* Shuffle the data, and use the random state specified in the PrairieLearn question page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "random_state = 14\n",
    "Xtr, Xts, ytr, yts = train_test_split(X, y, test_size=0.3, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some of the mice, some gene expression levels are missing. We will fill in the missing entries using  using the median values from the non-missing data *in the training set only*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "med_values = np.nanmedian(Xtr, axis=0)\n",
    "Xtr_filled = np.nan_to_num(Xtr, nan=med_values)\n",
    "Xts_filled = np.nan_to_num(Xts, nan=med_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since many of the genes may be irrelevant for predicting whether or not a mouse has Down Syndrome, we can use L1 regularization to \"de-select\" some features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qs_Ffz4rGIv"
   },
   "source": [
    "In an `sklearn` `LogisticRegression`, the hyperparameter `C` controls the \"strength\" of the regularization term in the objective function. `C` is the **inverse** of the regularization strength; a greater value of `C` means the model is *less* regularized.\n",
    "\n",
    "We will evaluate models for the following values of `C`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qyRyL0G4rGIv"
   },
   "outputs": [],
   "source": [
    "C_test = np.logspace(-1,3,10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bgfdNOnyrGIw"
   },
   "source": [
    "In the following cells, we are going to set up a K-fold CV to select a value of `C`.  First, we will set up an array to hold the results of each model in each fold. (Note that our K-fold CV will use 3 folds.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cDTUJvF1rGIw"
   },
   "outputs": [],
   "source": [
    "nfold = 3\n",
    "acc_val = np.zeros((len(C_test), nfold))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a KFold object using the `sklearn` implementation. Use 3 folds (and don't shuffle the data inside the K-Fold CV). \n",
    "\n",
    "When using a regularized model, we should standardize the data (remove the mean and scale to unit variance) first. Use the `sklearn` implementation of a `StandardScaler` to standardize data in each fold. Save the results in `Xtr_std` and `Xvl_std`.\n",
    "\n",
    "Use this to evalute an `sklearn` `LogisticRegression` regression model for each of the `C` values in `C_test`, and save the validation accuracy inside `acc_val`. In the `LogisticRegression`, \n",
    "\n",
    "* specify `solver = 'liblinear'`\n",
    "* specify `penalty = 'l1'`\n",
    "* specify `random_state` again (using the value from the PrairieLearn question page)\n",
    "\n",
    "and leave other hyperparameters and settings at their default values, except for `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YrExE062zb-U"
   },
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "\n",
    "\n",
    "# For each C in the list, fit a LogisticRegression model\n",
    "for iC, C in enumerate(C_test): \n",
    "    kf = KFold(n_splits=nfold, shuffle=False)\n",
    "    # For each fold\n",
    "    for ifold, (Itr, Ival) in enumerate(kf.split(Xtr_filled)):\n",
    "        Xtr_fold, Xval_fold = Xtr_filled[Itr], Xtr_filled[Ival]\n",
    "        ytr_fold, yval_fold = ytr[Itr], ytr[Ival]\n",
    "        \n",
    "        scaler = StandardScaler().fit(Xtr_fold)\n",
    "        Xtr_std = scaler.transform(Xtr_fold)\n",
    "        Xvl_std = scaler.transform(Xval_fold)\n",
    "        \n",
    "        clf = LogisticRegression(random_state = random_state, solver = 'liblinear', penalty='l1', C = C)\n",
    "        clf.fit(Xtr_std, ytr_fold)\n",
    "        yhat = clf.predict(Xvl_std)\n",
    "        \n",
    "        # update the appropriate entry in acc_val\n",
    "        acc_val[iC, ifold] = accuracy_score(yval_fold, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbRkU6KFzh0B"
   },
   "source": [
    "Next, compute the mean validation accuracy for each of the models, and identify the value of `C` for which the validation accuracy is maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vHW4H0qzhJR",
    "outputId": "97b0b643-9f46-40cb-be1f-b9852cc62f13"
   },
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "acc_mean = np.mean(acc_val, axis=1)\n",
    "C_best = C_test[np.argmax(acc_mean)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5h6aK0LWxwju"
   },
   "source": [
    "Using the `C` value you identified in the previous step (and other logistic regression parameters as specified earlier), we will fit a logistic regression model on the entire training set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, fit a `StandardScaler` on the entire training set, and use it to standardize both the training and test sets. Save the results in `Xtr_std` and `Xts_std`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "scaler = StandardScaler().fit(Xtr_filled)\n",
    "Xtr_std = scaler.transform(Xtr_filled)\n",
    "Xts_std = scaler.transform(Xts_filled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, fit a logistic regression model with the \"best\" C, and get its test set prediction in `y_hat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uERiNS8YyDpW"
   },
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "clf_best = LogisticRegression(random_state = random_state, solver = 'liblinear', penalty='l1', C = C_best)\n",
    "clf_best.fit(Xtr_std, ytr)\n",
    "y_hat = clf_best.predict(Xts_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_Attribution_: Based on a question by Professor Sundeep Rangan."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
