{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a model on time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workspace, you will load in a time series data set related to air quality. You will try out different ways of splitting this data into a training set (for model fitting) and test set (for model evaluation on \"new data\"), each time observing the effect on model performance.\n",
    "\n",
    "> In the notebook, specify random_state = 8 in the cell where it is indicated.\n",
    "\n",
    "| Name| \tType| \tDescription |\n",
    "| --- | --- | --- |\n",
    "|`Xtr_one_shuf`|\t2d numpy array|\tTraining data (features) for single shuffled split.|\n",
    "|`ytr_one_shuf`|\t1d numpy array|\tTraining data (target) for single shuffled split.|\n",
    "|`Xts_one_shuf`|\t2d numpy array| Test data (features) for single shuffled split.|\n",
    "|`yts_one_shuf`|\t1d numpy array|\tTest data (target) for single shuffled split.|\n",
    "|`yts_one_shuf_pred`|\t1d numpy array|\tTest data (target) predictions for single shuffled split.|\n",
    "|`r2_one_shuf`|\tfloat|\tR2 score for test data for single shuffled split.|\n",
    "|`Xtr_one_order`|\t2d numpy array|\tTraining data (features) for single ordered split.|\n",
    "|`ytr_one_order`|\t1d numpy array|\tTraining data (target) for single ordered split.|\n",
    "|`Xts_one_order`|\t2d numpy array|\tTest data (features) for single ordered split.|\n",
    "|`yts_one_order`|\t1d numpy array|\tTest data (target) for single ordered split.|\n",
    "|`yts_one_order_pred`|\t1d numpy array|\tTest data (target) predictions for single ordered split.|\n",
    "|`r2_one_order`|\tfloat|\tR2 score for test data for single ordered split.|\n",
    "|`r2_kf_shuffle`|\t1d numpy array|\tTest R2 score of each fold, shuffled split.|\n",
    "|`r2_kf_shuffle_mean`|\tfloat|\tMean R2 score across folds, shuffled split.|\n",
    "|`r2_ts`|\t1d numpy array|\tTest R2 score of each fold, time series split.|\n",
    "|`r2_ts_mean`|\tfloat|\tMean R2 score across folds, time series split.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will load in a dataset representing sensor readings and reference concentration of various compounds in the air. The data was collected over a period of around one year (2004-2005). The columns in the dataset include:\n",
    "\n",
    "1. Date: the date of the observation\n",
    "2. Time: the time of the observation\n",
    "3. CO(GT): the ground truth of the carbon monoxide level\n",
    "4. PT08.S1(CO): the level of carbon monoxide observed by the sensor\n",
    "4. NMHC(GT): the ground truth of the non-methane hydrocarbon level\n",
    "5. C6H6(GT): the ground truth of the benzene level\n",
    "6. PT08.S2(NMHC): the level of non-methane hydrocarbons observed by the sensor\n",
    "7. NOx(GT): the ground truth of the nitrogen oxides level\n",
    "8. PT08.S3(NOx): the level of nitrogen oxides observed by the sensor\n",
    "9. NO2(GT): the ground truth of the nitrogen dioxide level\n",
    "10. PT08.S4(NO2): the level of nitrogen dioxide observed by the sensor\n",
    "11. PT08.S5(O3): the level of ozone observed by the sensor\n",
    "12. T: the temperature\n",
    "13. RH: the relative humidity\n",
    "14. AH: the absolute humidity\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset may be used for several regression tasks. In this notebook, we will use linear regression to predict the NO2 (nitrogen dioxide) level, given the values in the weather-related columns, and the hour of day."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read in the data.  Note the following data processing steps that are included in the cell below:\n",
    "\n",
    "* This file includes some numeric values that use the comma `,` in place of a period `.` to denote decimals. `pandas` has a `decimal` argument to support this variation. \n",
    "* Some columns are empty, and some rows have missing data - we will drop these. We will also drop rows that have a `-200` in the target variable, since according to the data dictionary, these indicate missing values.\n",
    "* We will convert the `Date` and `Time` columns to a single `DateTime`, and we will make sure the data is then sorted by this `DateTime`.\n",
    "* We will add an `Hour` feature. Since the hour is cyclical, we will encode it using `sin` and `cos`, so that 23:00 is as close to 00:00 as it is to 22:00. (This is a common approach for cyclical features.)\n",
    "* We will also add a `Weekday` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('AirQualityUCI.csv', sep=\";\" , decimal=\",\")\n",
    "\n",
    "# drop columns and rows with missing values\n",
    "df.dropna(how=\"all\",axis=1,inplace=True)\n",
    "df.dropna(how=\"all\",axis=0,inplace=True)\n",
    "# in this data, a -200 value indicates a missing value - drop these, too\n",
    "df = df[df[\"NO2(GT)\"]!=-200]\n",
    "\n",
    "# create DateTime out of Date and Time\n",
    "df[\"DateTime\"] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format=\"%d/%m/%Y %H.%M.%S\")\n",
    "# set the DateTime column as the index\n",
    "df = df.set_index(\"DateTime\")\n",
    "# drop the Date and Time columns\n",
    "df = df.drop([\"Date\", \"Time\"], axis=1)\n",
    "# sort by DateTime\n",
    "df = df.sort_index()\n",
    "\n",
    "# add Hour feature\n",
    "df['HourSin'] = np.sin(df.index.hour*(2.*np.pi/24))\n",
    "df['HourCos'] = np.cos(df.index.hour*(2.*np.pi/24))\n",
    "# add Weekday feature\n",
    "df['Weekday'] = df.index.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>HourSin</th>\n",
       "      <th>HourCos</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-03-10 18:00:00</th>\n",
       "      <td>2.6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 19:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 20:00:00</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 21:00:00</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 22:00:00</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)  \\\n",
       "DateTime                                                                      \n",
       "2004-03-10 18:00:00     2.6       1360.0     150.0      11.9         1046.0   \n",
       "2004-03-10 19:00:00     2.0       1292.0     112.0       9.4          955.0   \n",
       "2004-03-10 20:00:00     2.2       1402.0      88.0       9.0          939.0   \n",
       "2004-03-10 21:00:00     2.2       1376.0      80.0       9.2          948.0   \n",
       "2004-03-10 22:00:00     1.6       1272.0      51.0       6.5          836.0   \n",
       "\n",
       "                     NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  \\\n",
       "DateTime                                                            \n",
       "2004-03-10 18:00:00    166.0        1056.0    113.0        1692.0   \n",
       "2004-03-10 19:00:00    103.0        1174.0     92.0        1559.0   \n",
       "2004-03-10 20:00:00    131.0        1140.0    114.0        1555.0   \n",
       "2004-03-10 21:00:00    172.0        1092.0    122.0        1584.0   \n",
       "2004-03-10 22:00:00    131.0        1205.0    116.0        1490.0   \n",
       "\n",
       "                     PT08.S5(O3)     T    RH      AH   HourSin       HourCos  \\\n",
       "DateTime                                                                       \n",
       "2004-03-10 18:00:00       1268.0  13.6  48.9  0.7578 -1.000000 -1.836970e-16   \n",
       "2004-03-10 19:00:00        972.0  13.3  47.7  0.7255 -0.965926  2.588190e-01   \n",
       "2004-03-10 20:00:00       1074.0  11.9  54.0  0.7502 -0.866025  5.000000e-01   \n",
       "2004-03-10 21:00:00       1203.0  11.0  60.0  0.7867 -0.707107  7.071068e-01   \n",
       "2004-03-10 22:00:00       1110.0  11.2  59.6  0.7888 -0.500000  8.660254e-01   \n",
       "\n",
       "                     Weekday  \n",
       "DateTime                      \n",
       "2004-03-10 18:00:00        2  \n",
       "2004-03-10 19:00:00        2  \n",
       "2004-03-10 20:00:00        2  \n",
       "2004-03-10 21:00:00        2  \n",
       "2004-03-10 22:00:00        2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will prepare the feature and target variables. We will train a linear regression model to predict the amount of Nitrogen Dioxide present at ground-level. This data is stored in the `NO2(GT)` column. Hence, this will be your target variable. We also specify the columns that we will use as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"T\", \"RH\", \"AH\", \"HourSin\", \"HourCos\", \"Weekday\"]].values\n",
    "y = df[\"NO2(GT)\"].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will evaluate several ways to divide the data into a training set (for fitting the parameters of the linear regression model) and a test set (for evaluating the model)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single split - random shuffle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll try a single split, and we will shuffle the data when distributing it into training and test sets.\n",
    "\n",
    "In the following cell, set the `random_state` variable to the value given in the question page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the `sklearn` implementation of `train_test_split` to split `X` and `y`, and save the results in: `Xtr_one_shuf`, `Xts_one_shuf`, `ytr_one_shuf`, `yts_one_shuf`.\n",
    "\n",
    "Use 1/5 of the data for the test set, and 4/5 for the training set. Also, use the random state in the variable you just defined, so that your result will match the graders'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (enter your code in this cell - DO NOT DELETE THIS LINE)\n",
    "Xtr_one_shuf, Xts_one_shuf, ytr_one_shuf, yts_one_shuf = train_test_split(X, y, test_size=1/5, random_state=random_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, train a linear regression model on the shuffled training data, then evaluate the R2 score of the model on the shuffled test data. Save this R2 value in `r2_one_shuf`. Also, save the model predictions on the test data in `yts_one_shuf_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (enter your code in this cell - DO NOT DELETE THIS LINE)\n",
    "model = LinearRegression()\n",
    "model.fit(Xtr_one_shuf, ytr_one_shuf)\n",
    "yts_one_shuf_pred = model.predict(Xts_one_shuf)\n",
    "r2_one_shuf = r2_score(yts_one_shuf, yts_one_shuf_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3147067763912289\n"
     ]
    }
   ],
   "source": [
    "print(r2_one_shuf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single split - sorted data, no shuffle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll try a single split again, but this time we will specify the value of the `shuffle` argument to `train_test_split` in order to *not* shuffle the data when distributing it into training and test sets. Since the data is sorted by `DateTime`, this means that the earlier values will be in the training set, and the last values will be in the test set.\n",
    "\n",
    "Again, use 1/5 of the data for the test set, and 4/5 for the training set. \n",
    "\n",
    "Save the results in: `Xtr_one_order`, `Xts_one_order`, `ytr_one_order`, `yts_one_order`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (enter your code in this cell - DO NOT DELETE THIS LINE)\n",
    "Xtr_one_order, Xts_one_order, ytr_one_order, yts_one_order = train_test_split(X, y, test_size=1/5, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, train a linear regression model on the ordered training data, then evaluate the R2 score of the model on the ordered test data. Save this R2 value in `r2_one_order`. Also, save the model predictions on the test set in `yts_one_order_pred`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (enter your code in this cell - DO NOT DELETE THIS LINE)\n",
    "model = LinearRegression()\n",
    "model.fit(Xtr_one_order, ytr_one_order)\n",
    "yts_one_order_pred = model.predict(Xts_one_order)\n",
    "r2_one_order = r2_score(yts_one_order, yts_one_order_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03077375532439519\n"
     ]
    }
   ],
   "source": [
    "print(r2_one_order)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple splits - random shuffle\n",
    "\n",
    "You might be concerned that your model training and validation uses only a single split of the data - it is possible that this split is not representative. To address this concern, we can use K-fold cross validation - not for model selection, but just for observing the results of this splitting and training process for different splits.\n",
    "\n",
    "We will use the `sklearn` library's `KFold` implementation, with K=5 (five splits of `X` and `y`)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, define a `KFold` with 5 splits, the random state set by the variable you defined earlier, and with the data shuffled. Then, iterate over the folds and in each iteration:\n",
    "\n",
    "* train a linear regression model on the training data for this fold\n",
    "* compute the R2 score of the model on the test data for this fold, and save the result in the appropriate element of `r2_kf_shuffle`\n",
    "\n",
    "Finally, compute the mean R2 score across all folds and save the result in `r2_kf_shuffle_mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (enter your code in this cell - DO NOT DELETE THIS LINE)\n",
    "\n",
    "# prepare an array for holding the results\n",
    "n_fold = 5\n",
    "r2_kf_shuffle = np.zeros(shape=(n_fold,))\n",
    "\n",
    "# Define a KFold CV with shuffle\n",
    "kf = KFold(n_splits=n_fold, shuffle=True, random_state=random_state)\n",
    "           \n",
    "for i, idx in enumerate(kf.split(X)):\n",
    "    idx_tr, idx_ts = idx\n",
    "    X_train_kfold = X[idx_tr]\n",
    "    y_train_kfold = y[idx_tr]\n",
    "    X_test_kfold = X[idx_ts]\n",
    "    y_test_kfold = y[idx_ts]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_kfold, y_train_kfold)\n",
    "\n",
    "    y_pred_kfold = model.predict(X_test_kfold)\n",
    "    r2_kf_shuffle[i] = r2_score(y_test_kfold, y_pred_kfold)\n",
    "    \n",
    "r2_kf_shuffle_mean = np.mean(r2_kf_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31470678 0.30545552 0.32868634 0.34387973 0.31956869]\n",
      "0.322459411332363\n"
     ]
    }
   ],
   "source": [
    "print(r2_kf_shuffle)\n",
    "print(r2_kf_shuffle_mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple splits - time series\n",
    "\n",
    "Finally, we'll repeat the multi-split evaluation, but using the `sklearn` library's [`TimeSeriesSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html). Here is the description from the module documentation:\n",
    "\n",
    "> Provides train/test indices to split time series data samples that are observed at fixed time intervals, in train/test sets. In each split, test indices must be higher than before, and thus shuffling in cross validator is inappropriate.\n",
    "> \n",
    "> This cross-validation object is a variation of KFold. In the kth split, it returns first k folds as train set and the (k+1)th fold as test set.\n",
    "> \n",
    "> Note that unlike standard cross-validation methods, successive training sets are supersets of those that come before them.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, define a `TimeSeriesSplit` with 5 splits. Then, iterate over the splits and in each iteration:\n",
    "\n",
    "* train a linear regression model on the training data for this fold\n",
    "* compute the R2 score of the model on the test data for this fold, and save the result in the appropriate element of `r2_ts`\n",
    "\n",
    "Finally, compute the mean R2 score across all folds and save the result in `r2_ts_mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (enter your code in this cell - DO NOT DELETE THIS LINE)\n",
    "\n",
    "# prepare an array for holding the results\n",
    "n_fold = 5\n",
    "r2_ts = np.zeros(shape=(n_fold,))\n",
    "\n",
    "# Define a TimeSeriesSplit \n",
    "ts = TimeSeriesSplit(n_splits=n_fold)\n",
    "\n",
    "for i, idx in enumerate(ts.split(X)):\n",
    "    idx_tr, idx_ts = idx\n",
    "    X_train = X[idx_tr]\n",
    "    y_train = y[idx_tr]\n",
    "    X_test = X[idx_ts]\n",
    "    y_test = y[idx_ts]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2_ts[i] = r2_score(y_test, y_pred)\n",
    "\n",
    "r2_ts_mean = np.mean(r2_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.22619877  0.11744013  0.1668679  -0.19125143  0.0063742 ]\n",
      "0.06512591500308551\n"
     ]
    }
   ],
   "source": [
    "print(r2_ts)\n",
    "print(r2_ts_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
