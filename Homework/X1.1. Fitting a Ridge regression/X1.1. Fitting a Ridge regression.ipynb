{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LNsV2yyFrGIs"
   },
   "source": [
    "# Train a `Ridge` Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are developing a machine learning model to predict diamond prices. However, you notice that the dataset of diamond features has many correlated variables, so you are using a **Ridge** regression (linear model with L2 regularization) to manage the variance of the model.\n",
    "\n",
    "In the attached workspace, you will read data from a file, and split it into training and test sets. Then, you will fit a **Ridge** model (using the sklearn implementation, you may refer to its documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)) on the training set, and evaluate its accuracy in on a test set.\n",
    "\n",
    "You'll need to specify this random state in your notebook: \n",
    "> random_state = 27\n",
    "\n",
    "and this value of Î±, the strength of the regularization parameter:\n",
    "> alpha = 2\n",
    "\n",
    "The following items will be graded:\n",
    "\n",
    "| Name | Type | Description |\n",
    "| ---- | ---- | ---- |\n",
    "|`Xtr` |\tpandas data frame\t| Training data (features).|\n",
    "|`Xts` |\tpandas data frame\t| Test data (features).|\n",
    "|`ytr`\t| pandas series OR pandas data frame OR 1d numpy array\t| Training data (target).|\n",
    "|`yts`\t| pandas series OR pandas data frame OR 1d numpy array\t| Test data (target).|\n",
    "|`Xtr_std`\t| 2d numpy array\t| Training data (features) after standardizing.|\n",
    "|`Xts_std`\t| 2d numpy array\t| Test data (features) after standardizing.|\n",
    "|`yts_hat`\t| 1d numpy array\t| Model prediction for test data.|\n",
    "|`mse`\t| float\t| MSE of model on test data.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LhRjDo48rGIt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z78jhR20rGIu"
   },
   "source": [
    "In this notebook, we are interested in predicting the price of a diamond from its physical characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Zj0UjAsTrGIv"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('diamonds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a quick view of the columns in this data by runnning the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53940 entries, 0 to 53939\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   carat    53940 non-null  float64\n",
      " 1   cut      53940 non-null  object \n",
      " 2   color    53940 non-null  object \n",
      " 3   clarity  53940 non-null  object \n",
      " 4   depth    53940 non-null  float64\n",
      " 5   table    53940 non-null  float64\n",
      " 6   price    53940 non-null  int64  \n",
      " 7   x        53940 non-null  float64\n",
      " 8   y        53940 non-null  float64\n",
      " 9   z        53940 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(3)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains information about 53,940 round-cut diamonds. It includes variables measuring various pieces of information about the diamonds. \n",
    "\n",
    "There are 3 variables with an ordered factor structure: `cut`, `color`, & `clarity`.\n",
    "\n",
    "* `cut` can be, from worst to best: Fair, Good, Very Good, Premium, Ideal\n",
    "* `color` can range from J (worst) to D (best)\n",
    "* `clarity` can be I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best)\n",
    "\n",
    "There are 6 variables that are of numeric structure: `carat`, `depth`, `table`, `x`, `y`, `z`. These relate to the physical size of the diamond.\n",
    "\n",
    "* `carat` is the weight of the diamond\n",
    "* `depth` is the total depth percentage\t\n",
    "* `table` gives the width of top of diamond relative to widest point\n",
    "* `x`, `y`, and `z` are the length, width, and depth in mm, respectively.\n",
    "\n",
    "\n",
    "Finally, the `price` variable (which will be our target variable in this analysis) is also numeric, and gives the price of the diamond in US dollars.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell maps the three categorical variables to numeric equivalents according to their order, so that we can use them in our regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cut\"] = df[\"cut\"].map({\"Fair\": 1, \"Good\": 2, \"Very Good\": 3, \"Premium\": 4, \"Ideal\": 5})\n",
    "df[\"color\"] = df[\"color\"].map({\"J\": 1, \"I\": 2, \"H\": 3, \"G\": 4, \"F\": 5, \"E\": 6, \"D\": 7})\n",
    "df[\"clarity\"] = df[\"clarity\"].map({\"I1\": 1, \"SI2\": 2, \"SI1\": 3, \"VS2\": 4, \"VS1\": 5, \"VVS2\": 6, \"VVS1\": 7, \"IF\": 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, the cell below will read the names of the columns we want to use as features into an array called `x_names`, and the name of the column we want to use as the target will be read into `y_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'x', 'y', 'z']\n",
    "y_names = ['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `df`, `x_names`, and `y_names`, split the data into training and test sets using `sklearn`'s implementation of `train_test_split`. \n",
    "\n",
    "* Reserve 30% of the data for testing, and leave 70% for training.\n",
    "* Shuffle the data, and use the random state specified in the PrairieLearn question page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "random_state = 27\n",
    "Xtr, Xts = train_test_split(df[x_names], test_size=0.3, random_state = random_state, shuffle = True)\n",
    "ytr, yts = train_test_split(df[y_names], test_size=0.3, random_state = random_state, shuffle = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using a regularized model, we always standardize the data (remove the mean and scale to unit variance) first. Use the `sklearn` implementation of a `StandardScaler`. Save the results in `Xtr_std` and `Xts_std`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "scaler = StandardScaler().fit(Xtr)\n",
    "Xtr_std = scaler.transform(Xtr)\n",
    "Xts_std = scaler.transform(Xts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bgfdNOnyrGIw"
   },
   "source": [
    "Now we are ready to fit the `Ridge` model. \n",
    "\n",
    "* Specify the `random_state` as indicated in the PrairieLearn question page\n",
    "* Specify the `alpha` as indicated in the PrairieLearn question page\n",
    "* Leave other settings unspecified, so that the default values will be used\n",
    "\n",
    "and fit the model on the training data. Then, use it to make predictions for the test samples, and save this prediction in `yts_hat`. Evaluate the MSE of the model on the test data, and save this in `mse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "random_state = 27\n",
    "alpha = 2\n",
    "model = Ridge(alpha=alpha, random_state=random_state)\n",
    "model.fit(Xtr_std, ytr)\n",
    "yts_hat = model.predict(Xts_std)\n",
    "mse = mean_squared_error(yts, yts_hat)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
