{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting false statements with L1-regularized logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have been hired by a news wire service to train a machine learning model to identify potentially false statements and claims made by public figures. These statements will be flagged for additional fact-checking by a human fact checker.\n",
    "\n",
    "To train your model, you are given a dataset of already-fact-checked statements from the past decade, half of which have been evaluated as true and half of which have been evaluated as false.\n",
    "\n",
    "In the attached workspace, you will load in this data, then use it to train a [LogisticRegression](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html) model. Since the text data has many features once converted to a \"bag of words\" representation, you will also explore the use of L1 regularization.\n",
    "\n",
    "> Note: your code will be evaluated on a random array of C values! For this reason, the grader feedback may change even if your code does not (e.g. for one random array of values, you might happen to get the correct result even with incorrect code; but for another random array, you do not.).\n",
    "\n",
    "| Name | Type | Description |\n",
    "| ---- | ---- | ---- |\n",
    "|Xtr_vec\t|2d numpy array\t|Vector representation of training data.|\n",
    "|Xts_vec\t|2d numpy array\t|Vector representation of test data.|\n",
    "|acc_val\t|2d numpy array\t|Accuracy of LogisticRegression model for each fold and each value of C.|\n",
    "|C_best\t|float\t|Value of C for which the validation accuracy is highest.|\n",
    "|acc_best\t|float\t|Test accuracy of model trained with C_best.|\n",
    "|count_best\t|int\t|Number of non-zero coefficients of model trained with C_best.|\n",
    "|C_one_se\t|float\t|Value of C to use according to one-SE rule.|\n",
    "|acc_one_se\t|float\t|Test accuracy of model trained with C_one_se.|\n",
    "|count_one_se\t|int\t|Number of non-zero coefficients of model trained with C_one_se.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z2TkU89M0Ar6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_factcheck.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame includes\n",
    "\n",
    "*  a `statement` field, which has the text of the statement, \n",
    "* and a `label_binary` field indicating if it is false (1) or true/mostly true (0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>label_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>Nearly one in four people in their prime worki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>More than 43 percent of all food stamps are gi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Gov. Chris Christie owes the state money for a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>In Harrisburg, I passed more bills than all th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Says Barack Obama said, If we keep talking abo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              statement  label_binary\n",
       "1352  Nearly one in four people in their prime worki...             0\n",
       "286   More than 43 percent of all food stamps are gi...             1\n",
       "756   Gov. Chris Christie owes the state money for a...             1\n",
       "1472  In Harrisburg, I passed more bills than all th...             0\n",
       "701   Says Barack Obama said, If we keep talking abo...             1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into a training and test set. Note that the data is ordered by class, so we *must* shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_str, Xts_str, ytr, yts = train_test_split(df['statement'].values, df['label_binary'].values, shuffle=True, random_state=0, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, we will need to get this text into some kind of numeric representation. We will use a basic approach called \"bag of words\", that works as follows:\n",
    "\n",
    "0. Remove the \"trivial\" words that you want to ignore, such as \"the\", \"an\", \"has\", etc. from the text.\n",
    "1. Compile a \"vocabulary\" - a list of all of the words in the dataset - with integer indices from 0 to $d-1$.\n",
    "2. Convert every sample into a $d$-dimensional vector $x$, by letting the $j$ th coordinate of $x$ be the number of occurences of the $j$ th words in the document. (This number is often called the \"term frequency\".)\n",
    "\n",
    "Now, we have a set of vectors - one for each sample - containing the frequency of each word."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `sklearn` implementation of this, which is called `CountVectorizer`. You may refer to the [`CountVectorizer` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html).\n",
    "\n",
    "We will create an instance of a `CountVectorizer`, passing `stop_words = 'english'` and leaving other arguments at their default values.\n",
    "\n",
    "Create `Xtr_vec` by fitting it on the training data, then using it to transform the training data. Use the already fitted vectorizer to transform the test data, to create `Xts_vec`. (This is the 'typical' data pre-processing pattern, where data pre-processing always uses the statistics of the training data *only*.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "vec = CountVectorizer(stop_words='english')\n",
    "Xtr_vec = vec.fit_transform(Xtr_str)\n",
    "Xts_vec = vec.transform(Xts_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 4569)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr_vec.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You notice that in its vector representation, the data has several thousand features. You wonder if maybe you can use a sparse representation of this data in your classifier. You decide to try L1 regularization, which you know tends to fit sparse coefficients."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, use K-fold CV with 5 folds to evaluate different values of `C` in the list defined by\n",
    "\n",
    "```\n",
    "np.logspace(-3, 3, num=20)\n",
    "```\n",
    "\n",
    "for an `l1` penalty in the `LogisticRegression`.  Iterate over the K-fold split (don't shuffle the data again!) and in each fold:\n",
    "\n",
    "* train a `LogisticRegression` with an `l1` penalty and the specified value of `C`. Also set `random_state = 0`, and use the `liblinear` solver. Leave other settings at their default values.\n",
    "* compute the accuracy of the model on the validation data, and save it in `acc_val`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_test = np.logspace(-3, 3, num=20)\n",
    "# Note: use this C_test array to implement your solution, and do *not* re-define C_test.\n",
    "# The grader will evaluate your solution over a *DIFFERENT* array, that is also named C_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "\n",
    "nfold = 5\n",
    "acc_val = np.zeros((len(C_test), nfold))\n",
    "\n",
    "kf = KFold(n_splits=nfold)\n",
    "\n",
    "# For each fold\n",
    "for ifold, (Itr, Ival) in enumerate(kf.split(Xtr_vec)):\n",
    "    # For each C in the list, fit a LogisticRegression model\n",
    "    for iC, C in enumerate(C_test):\n",
    "        clf  = LogisticRegression(random_state = 0, penalty='l1', solver='liblinear', C = C)\n",
    "        clf.fit(Xtr_vec[Itr], ytr[Itr])\n",
    "        yhat = clf.predict(Xtr_vec[Ival])\n",
    "        # update the appropriate entry in acc_val\n",
    "        acc_val[iC, ifold] = accuracy_score(ytr[Ival], yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the value of C that had the best validation accuracy, and save it in `C_best`. (Note: do not hard-code this value!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "# C_best = ...\n",
    "acc_mean = np.mean(acc_val, axis=1)\n",
    "C_best = C_test[np.argmax(acc_mean)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the entire training set, train a `LogisticRegression` with `l1` penalty and this value of `C`, `random_state = 0`, `liblinear` solver, and leave other settings at their default values. Get the accuracy of this model on the test data, and save it in `acc_best`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "# acc_best = ..\n",
    "model_best = LogisticRegression(penalty='l1', C=C_best, random_state=0, solver='liblinear')\n",
    "model_best.fit(Xtr_vec, ytr)\n",
    "y_pred_best = model_best.predict(Xts_vec)\n",
    "acc_best = accuracy_score(yts, y_pred_best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also check whether this model achieves your goal of \"zeroing\" out many features - use [`np.count_nonzero`](https://numpy.org/doc/stable/reference/generated/numpy.count_nonzero.html) to count the number of model coefficients that are *not* zero. Save this count in `count_best`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "# count_best = ..\n",
    "count_best = np.count_nonzero(model_best.coef_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, find the value of C that is best according to the one-SE rule, and save it in `C_one_se`. (Note: do not hard-code this value!) Remember that C is the *inverse* of the strength of the regularization penalty, e.g. a larger value of C means *less* regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "# C_one_se = ...\n",
    "acc_mean = acc_val.mean(axis=1)\n",
    "acc_std = acc_val.std(axis=1)\n",
    "acc_one_se = acc_mean - acc_std\n",
    "C_one_se = C_test[np.argmax(acc_mean >= np.max(acc_one_se))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the entire training set, train a `LogisticRegression` with `l1` penalty and this value of `C`, `random_state = 0`, `liblinear` solver, and leave other settings at their default values. Get the accuracy of this model on the test data, and save it in `acc_one_se`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "# acc_one_se = ..\n",
    "model_one_se = LogisticRegression(penalty='l1', C=C_one_se, random_state=0, solver='liblinear')\n",
    "model_one_se.fit(Xtr_vec, ytr)\n",
    "y_pred_one_se = model_one_se.predict(Xts_vec)\n",
    "acc_one_se = accuracy_score(yts, y_pred_one_se)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also check whether this model achieves your goal of \"zeroing\" out many features - use [`np.count_nonzero`](https://numpy.org/doc/stable/reference/generated/numpy.count_nonzero.html) to count the number of model coefficients that are *not* zero. Save this count in `count_one_se`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "# count_one_se = ..\n",
    "count_one_se = np.count_nonzero(model_one_se.coef_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Workbook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
